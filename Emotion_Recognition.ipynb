{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lakshita2002/FER_brain_and_cognitive_society/blob/master/Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-z7SNu-y_vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "from mlxtend.image import extract_face_landmarks\n",
        "import gc\n",
        "#Essential Keras Functions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,MaxPooling2D,Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.backend import clear_session\n",
        "#Essential sklearn Functions\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G57_XIz4et7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LAKSHITA\n",
        "\n",
        "# loading images in the form of an array\n",
        "jaffe_dir_path = '/content/drive/My Drive/Images/'\n",
        "expres_code = ['NE','HA','AN','DI','FE','SA','SU']\n",
        "expressions = [ 0,   1,   2,   3,   4,   5,   6]\n",
        "img_names = []\n",
        "img_data_list = []\n",
        "labels = []\n",
        "\n",
        "img_list = os.listdir(jaffe_dir_path)\n",
        "for img in img_list:\n",
        "    input_img = cv2.imread(jaffe_dir_path + img, cv2.IMREAD_GRAYSCALE)\n",
        "    img_data_list.append(input_img)\n",
        "    \n",
        "img_data = np.array(img_data_list)\n",
        "\n",
        "print(img_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlE4AkiBSsy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_image(image,angle):\n",
        "    '''\n",
        "    Returns a rotated image given the angle(degrees) to be rotated and image\n",
        "    '''\n",
        "    rows,cols = image.shape\n",
        "    #Transformation Matrix(M)\n",
        "    M = cv2.getRotationMatrix2D(((rows - 1)/2.0,(cols - 1)/2.0),angle,1)\n",
        "    rot_img = cv2.warpAffine(image, M, (cols,rows))\n",
        "\n",
        "    return rot_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHnBfSCcVCsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_angle(point1, point2):\n",
        "    '''\n",
        "    To find angle in degrees for the given two points\n",
        "    '''\n",
        "    # angle in radians\n",
        "    angle_r = math.atan((point2[1] - point1[1])/(point2[0] - point1[0]))\n",
        "    # angle in degrees\n",
        "    angle_d = math.degrees(angle_r)\n",
        "\n",
        "    return angle_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0CMveFSZpSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eye_centers(landmarks):\n",
        "    '''\n",
        "    To find the eye centers(mean of the 6 landmark points around the eye)\n",
        "    '''\n",
        "    #36-41 are landmark points surrounding right eye\n",
        "    point1 = (np.mean(landmarks[36:42,0]),np.mean(landmarks[36:42,1]))\n",
        "    #42-47 are landmark points surrounding left eye\n",
        "    point2 = (np.mean(landmarks[42:48,0]),np.mean(landmarks[42:48,1]))\n",
        "\n",
        "    return point1, point2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUlto7nGX-uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(input_images):\n",
        "\n",
        "    '''\n",
        "    The preprocessing involves rotation of the image and image cropping\n",
        "    Arguments :\n",
        "    input_images -- array of images of shape (m,h,w)\n",
        "    Returns :\n",
        "    array of images after preprocessing\n",
        "    '''\n",
        "    preprocessed_faces = []\n",
        "    for img in input_images:\n",
        "        \n",
        "        #landmark detection\n",
        "        #(returns an array of landmarks of shape (68,2))\n",
        "        landmarks = extract_face_landmarks(img)\n",
        "\n",
        "        #detect eye cnters\n",
        "        p1, p2 = eye_centers(landmarks)\n",
        "\n",
        "        #find angle \n",
        "        angle = find_angle(p1, p2)\n",
        "        \n",
        "        #rotate image\n",
        "        rot_img = rotate_image(img, angle)\n",
        "\n",
        "        #find length 'd'\n",
        "        p1_new, p2_new = eye_centers(extract_face_landmarks(rot_img))\n",
        "        d = cv2.norm(np.array(p1_new) - np.array(p2_new))\n",
        "\n",
        "        #mid point of new eye centers\n",
        "        d_mid = ((p2_new[0] + p1_new[0])/2.0 , (p2_new[1] + p1_new[1])/2.0)\n",
        "\n",
        "        #point above line joining eye centers\n",
        "        x_up = d_mid[0]\n",
        "        y_up = d_mid[1] - (0.6*d)\n",
        "\n",
        "        #cropping image\n",
        "        x_start = int(landmarks[0,0])\n",
        "        x_end = int(landmarks[16,0])\n",
        "        y_start = int(y_up)\n",
        "        y_end = int(landmarks[8,1])\n",
        "\n",
        "        crop_img = img[y_start:y_end,x_start:x_end]\n",
        "\n",
        "        #resize the cropped image\n",
        "        face_roi = cv2.resize(crop_img,(48,48))\n",
        "        \n",
        "        preprocessed_faces.append(face_roi)\n",
        "\n",
        "    return np.array(preprocessed_faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbERjH0noO9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PRANAY\n",
        "def normalization(imagedata, mean, std_dev):\n",
        "    '''\n",
        "    To apply Histogram equalization and Z-Square Normalization to the preprocessed images\n",
        "    Arguments :\n",
        "    imagedata -- array of preprocessed images of shape (m,h,w)\n",
        "    mean -- mean of imagedata array\n",
        "    std_dev -- standard deviation of imagedata array\n",
        "    Returns :\n",
        "    array of normalized images of shape (m,48,48)\n",
        "    '''\n",
        "    normalized_images = []\n",
        "    for i in range(imagedata.shape[0]):\n",
        "        #Histogram Equalization\n",
        "        hist_eqv = cv2.equalizeHist(imagedata[i])\n",
        "\n",
        "        #Z-Square normalization\n",
        "        zsq_norm = ((hist_eqv - mean)/std_dev)\n",
        "\n",
        "        #Resize\n",
        "        resized_image = cv2.resize(zsq_norm, (48,48))\n",
        "        normalized_images.append(resized_image)\n",
        "\n",
        "    return np.array(normalized_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxLZqeN7ndIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KUSUM\n",
        "def data_aug(X_train,X_val,y_train,y_val,train_batch_size,val_batch_size):\n",
        "    '''\n",
        "    To apply data augmentation on training data.\n",
        "    Arguments :\n",
        "    X_train and X_val -- array of training and validation data containing images\n",
        "    y_train and y_val -- labels of training and validation images\n",
        "    train_batch_size and val_batch_size contains the batch size of images\n",
        "    Returns:\n",
        "    Iterator for training and validation batch \n",
        "    '''\n",
        "    #create image data augmenatation generator for training and validation data\n",
        "    train_datagen = ImageDataGenerator(rotation_range=2,\n",
        "                                       rescale=1.0,\n",
        "                                       horizontal_flip=True,\n",
        "                                       fill_mode='nearest')\n",
        "    \n",
        "    val_datagen = ImageDataGenerator(rescale=1.0)\n",
        "\n",
        "    #create iterator for training and validation data\n",
        "    train_batch = train_datagen.flow(X_train,y_train,batch_size=train_batch_size)\n",
        "\n",
        "\n",
        "    val_batch = val_datagen.flow(X_val,y_val,batch_size=val_batch_size)\n",
        "\n",
        "\n",
        "    return (train_batch,val_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seffdYbh85JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PRANAY\n",
        "def augmentation(imagedata):\n",
        "    '''\n",
        "    To increase the no. of images by Random rotation and Horizontal flipping\n",
        "    and all the images genarated are stored in the specified directory with proper name\n",
        "    Arguments :\n",
        "    imagedata -- array of images after preprocessing and normalization\n",
        "    '''\n",
        "\n",
        "    for i in range(imagedata.shape[0]):\n",
        "        img = imagedata[i].reshape(imagedata[i].shape + (1,))\n",
        "        img = array_to_img(img)#To convert to PIL image instance\n",
        "        img = img_to_array(img)\n",
        "        img = np.array([img])\n",
        "        \n",
        "        datagen = ImageDataGenerator(rotation_range = 3,horizontal_flip = True)\n",
        "\n",
        "        imgGen = datagen.flow(img, batch_size = 1, save_to_dir =\n",
        "                              'drive/My Drive/Augmented Images/jaffeaug',\n",
        "                              save_prefix = imagename[i], save_format='tiff')\n",
        "\n",
        "      for j in range(5): #generates 5 images per image\n",
        "        \n",
        "          batch = imgGen.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQHVrROAstYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KUSUM\n",
        "def datareshaping(normalized_data,labels):\n",
        "    '''\n",
        "    Expands the dimensions of the normalized_data and and one-hot encodes the target labels\n",
        "    Arguments:\n",
        "    normalized_data -- normalized_data obtained after preforming normalization and downsampling of shape (m,48,48)\n",
        "    labels -- contains the 1-dimensional array of labels\n",
        "    Returns:\n",
        "    expanded normalized data of shape(m,48,48,1) and one hot encoded target labels of shape(m,6)\n",
        "\n",
        "    '''\n",
        "    X = normalized_data\n",
        "    X = np.reshape(X ,(normalized_data.shape + (1,))\n",
        "\n",
        "    y = to_categorical(labels)\n",
        "    return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfiOZPdEp3SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recog_model(input_shape):\n",
        "    '''\n",
        "    Create the keras model architecture\n",
        "    Arguments:\n",
        "    input_shape -- The dimensions of the input data\n",
        "    Returns:\n",
        "    The created model\n",
        "    '''\n",
        "\n",
        "    # input placeholder as a tensor of input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # define the keras model\n",
        "    X = Conv2D(48, (5,5), strides = (1,1), padding = 'valid', name = 'conv1')(X_input)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = MaxPooling2D((2,2), strides = (2,2), padding = 'valid', name = 'maxpool1')(X)\n",
        "\n",
        "    X = Conv2D(64, (5,5), strides = (1,1), padding = 'valid', activation = 'relu', name = 'conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = MaxPooling2D((2,2), strides = (2,2), padding = 'valid', name = 'maxpool2')(X)\n",
        "\n",
        "    X = Flatten()(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(units = 7,activation = 'softmax',name = 'out',kernel_initializer = 'glorot_normal')(X)\n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X, name = 'recog_model')\n",
        "    sgd = SGD(learning_rate = 0.001, momentum = 0.9)\n",
        "\n",
        "    #compile the keras model\n",
        "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUDmOO5NccG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def traintestsplit(X,y):\n",
        "    '''\n",
        "    Splits the train and test data into 70:30 ratio\n",
        "    '''\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "    return X_train,X_test,y_train,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3afyqlj5OW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LAKSHITA\n",
        "\n",
        "# landmark identification\n",
        "for i in range (0,img_data[:,0,0].size ):\n",
        "\t\n",
        "\tfaces_in_image = detector(img_data[i], 0)\n",
        "\n",
        "\tfor face in faces_in_image:\n",
        "\n",
        "\t\tlandmarks = predictor(img_data[i], face)\n",
        "\n",
        "\t\tlandmarks_list = []\n",
        "\t\tfor j in range(0, landmarks.num_parts):\n",
        "\t\t\tlandmarks_list.append((landmarks.part(j).x, landmarks.part(j).y))\n",
        "\n",
        "\t\tfor landmark_num, xy in enumerate(landmarks_list, start = 1):\n",
        "\t\t\tcv2.circle(img_data[i], (xy[0], xy[1]), 1, (168, 0, 20), -1)\n",
        "\n",
        "cv2_imshow(img_data[157])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fob9pOfL5W-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LAKSHITA\n",
        "\n",
        "# image cropping\n",
        "cropped_images = preprocessing(img_data)\n",
        "cv2_imshow(cropped_images[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q14WsV78-vY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pranay,#Kusum\n",
        "def K_fold_cv(X_tmp, Y_tmp,n_splits = 10, batch_size = 16, epochs = 120):\n",
        "    '''\n",
        "    Applies K fold cross validation for given Training data\n",
        "    Returns the Mean and standard deviation of accuracies\n",
        "    '''\n",
        "  \n",
        "    i = 1\n",
        "    model_accuracies = []\n",
        "    for train_index, val_index in KFold(n_splits = n_splits, shuffle = True, random_state = 0).split(X_tmp, Y_tmp):\n",
        "      \n",
        "        X_train, X_val = X_tmp[train_index], X_tmp[val_index]\n",
        "        X_train = X_train.astype('float32')\n",
        "        X_val = X_val.astype('float32')\n",
        "        Y_train, Y_val = Y_tmp[train_index], Y_tmp[val_index]\n",
        "        \n",
        "        print('Model evaluation : ' + str(i))\n",
        "        \n",
        "        #create a model object\n",
        "        Recog_Model = recog_model(X_tmp.shape[1:])\n",
        "        #train the model\n",
        "        Recog_Model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs,\n",
        "                        shuffle = True, validation_data = (X_val, Y_val))\n",
        "        \n",
        "        #plotting validation loss and training loss vs epochs\n",
        "        loss_train = history.history['loss']\n",
        "        loss_val = history.history['val_loss']\n",
        "        epochs = range(epochs)\n",
        "        plt.plot(epochs, loss_train, 'g', label = 'training_loss')\n",
        "        plt.plot(epochs, loss_val, 'b', label = 'val_loss')\n",
        "        plt.title('Loss Vs Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'drive/My Drive/ER project/Jaffe(foldf{i})losses.png' )\n",
        "        plt.clf()\n",
        "\n",
        "        #plotting validation accuracy and training accuracy vs epochs\n",
        "        accuracy_train = history.history['accuracy']\n",
        "        accuracy_val = history.history['val_accuracy']\n",
        "        plt.plot(epochs, accuracy_train, 'g', label = 'training_accuracy')\n",
        "        plt.plot(epochs, accuracy_val, 'b', label = 'val_accuracy')\n",
        "        plt.title('Accuracy Vs Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'drive/My Drive/ER project/Jaffe(foldf{i})accuracies.png')\n",
        "        plt.clf()\n",
        "\n",
        "        metrics = Recog_Model.evaluate(X_val, Y_val)\n",
        "        print(f'Accuracy fold f{}: ' + str(metrics[1] * 100))\n",
        "        model_accuracies.append(metrics[1] * 100)\n",
        "        Recog_Model.save(f'drive/My Drive/ER project/Jaffe(foldf{i}).h5')\n",
        "        #Discard the present model\n",
        "        del Recog_Model\n",
        "\n",
        "        gc.collect()\n",
        "        clear_session()\n",
        "        i += 1\n",
        "\n",
        "    #calculating mean and standard deviation of accuracies\n",
        "    Mean_Accuracy = np.mean(model_accuracies)\n",
        "    standard_deviation = np.std(model_accuracies)\n",
        "\n",
        "    return Mean_Accuracy,standard_deviation"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}